<script src="./javascripts/face-api.js"></script>
<script src="./javascripts/commons.js"></script>
<script src="./javascripts/faceDetectionControls.js"></script>

<script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>

<div id="navbar" style="display:none;"></div>

<style>
    .webcam-pane {
        position: absolute;
        top: 0;
        right: 0;
    }
</style>


<div class="progress" id="loader">
    <div class="indeterminate"></div>
</div>
<div style="position: relative;padding:2px">
    <video onloadedmetadata="onPlay(this)" class="webcam-pane margin shadow-lg rounded" id="inputVideo" autoplay muted
        playsinline></video>
    <canvas class="webcam-pane margin" id="overlay" />
</div>

<script>
    let forwardTimes = []
    let withBoxes = true
    var topExpression;

    function onChangeHideBoundingBoxes(e) {
        withBoxes = !$(e.target).prop('checked')
    }

    function updateTimeStats(timeInMs) {
        forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
        const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
        $('#time').val(`${Math.round(avgTimeInMs)} ms`)
        $('#fps').val(`${faceapi.utils.round(1000 / avgTimeInMs)}`)
    }

    async function onPlay() {
        const videoEl = $('#inputVideo').get(0)

        if (videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
            return setTimeout(() => onPlay())


        const options = getFaceDetectorOptions()

        const ts = Date.now()

        const result = await faceapi.detectSingleFace(videoEl, options).withFaceExpressions()

        updateTimeStats(Date.now() - ts)

        if (result) {
            const canvas = $('#overlay').get(0)
            const dims = faceapi.matchDimensions(canvas, videoEl, true)

            const resizedResult = faceapi.resizeResults(result, dims)
            const minConfidence = 0.05
            if (withBoxes) {
                faceapi.draw.drawDetections(canvas, resizedResult)
            }
            faceapi.draw.drawFaceExpressions(canvas, resizedResult, minConfidence)

            var expressions = {}


            Object.keys(resizedResult['expressions']).forEach(function (key, index) {
                // key: the name of the object key
                // index: the ordinal position of the key within the object 
                console.log(key)
                var expConf = resizedResult['expressions'][key];
                var exp = key;

                if (expConf > 0 && expConf < 1.1) {
                    expressions[exp] = expConf;
                }

                if (expConf > 0.85) {
                    topExpression = exp;
                }

            });
        }

        setTimeout(() => onPlay())
    }

    async function run() {
        // load face detection and face expression recognition models
        await changeFaceDetector(TINY_FACE_DETECTOR)
        await faceapi.loadFaceExpressionModel('/')
        changeInputSize(224)

        // try to access users webcam and stream the images
        // to the video element
        const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
        const videoEl = $('#inputVideo').get(0)
        videoEl.srcObject = stream
    }

    function updateResults() { }

    $(document).ready(function () {
        renderNavBar('#navbar', 'webcam_face_expression_recognition')
        initFaceDetectionControls()
        run()
    })
</script>